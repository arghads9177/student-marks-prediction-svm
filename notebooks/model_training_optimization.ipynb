{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4bc40bd-1226-4b78-8714-5b79698a7442",
   "metadata": {},
   "source": [
    "# Student Marks Prediction\n",
    "\n",
    "## Description\n",
    "\n",
    "This project aims to predict the marks obtained by students based on their study time and the number of courses they have opted for. The dataset for this project has been downloaded from the UCI Machine Learning Repository. \n",
    "\n",
    "The dataset consists of a small number of instances and attributes, making it both simple and challenging. Despite the limited number of features and samples, the goal is to build a regression model that captures the patterns in the data while ensuring generalizability.\n",
    "\n",
    "## Properties of the Dataset:\n",
    "\n",
    "- **Number of Instances**: 100\n",
    "- **Number of Attributes**: 3 (including the target variable)\n",
    "\n",
    "## Objective:\n",
    "\n",
    "1. **Understand the Dataset & Cleanup**: Explore and clean the dataset as necessary.\n",
    "2. **Build Regression Models**: Develop regression models to predict student marks based on study time and number of courses.\n",
    "3. **Model Evaluation**: Evaluate the models using appropriate metrics like R-squared (R²), Root Mean Squared Error (RMSE), etc., and compare the results.\n",
    "\n",
    "## Source\n",
    "\n",
    "This dataset is available on Kaggle in the following link:\n",
    "> https://www.kaggle.com/datasets/yasserh/student-marks-dataset/data\n",
    "\n",
    "## Data Dictionary:\n",
    "\n",
    "- **number_courses**: Numeric data. This is the Number of Courses Opted by the student.\n",
    "- **time_study**: Numeric data. This is the Average Time Studied per day by the student (in hours).\n",
    "- **Marks**: Marks obtained by the student (target variable).\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "1. **Model Training**: The objective of model training is to train the model with the dataset so that it can predict the marks of student.\n",
    "2. **Model Evaluation**: Evaluate the performance of the trained model using different metrics like R2 Score, and find the loss or residual present in the model with Root Mean Squeared Error, Mean Squared Error and Mean Absolute Error.\n",
    "3. **Model Optimization**: The objective of model optimization is to find and optimal model for this dataset using Cross Validation and Hyperparameter Tuning to enhance the performance of the trained model and reduce the loss present in the model so that it can predict the marks of student accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166b4fea-b731-4622-bbca-19b771746134",
   "metadata": {},
   "source": [
    "### Load Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a344a64a-4611-4e79-a76b-7f2df33d0ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Model and Evaluation Metrics\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score, mean_absolute_error,mean_squared_error\n",
    "\n",
    "# Hyperparameter tuning\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b44c49-6b80-49ab-aad6-b11ba4c459ec",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d066160e-2019-4a04-8f39-8a479d551e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Path\n",
    "data_path = \"../data\"\n",
    "csv_path = os.path.join(data_path, \"Student_Marks.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7fb4b5-71ca-4af9-965d-8756d8c6368f",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b6b16e-9326-4f25-9062-311cf15fa6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb10d04b-f995-4571-86b4-d5ca633df569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_courses</th>\n",
       "      <th>time_study</th>\n",
       "      <th>Marks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>4.508</td>\n",
       "      <td>19.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.096</td>\n",
       "      <td>7.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3.133</td>\n",
       "      <td>13.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>7.909</td>\n",
       "      <td>53.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>7.811</td>\n",
       "      <td>55.299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_courses  time_study   Marks\n",
       "0               3       4.508  19.202\n",
       "1               4       0.096   7.734\n",
       "2               4       3.133  13.811\n",
       "3               6       7.909  53.018\n",
       "4               8       7.811  55.299"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530c39e3-d84c-4cee-8999-48eb297907e1",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "- Preprocessing is needed to do the following:\n",
    "    - Separate the input and output features present in the dataset.\n",
    "    - Split the data into training and testing purpose so that we can train the model with training data and evaluate the performance and loss with testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67848ed7-e935-4fb0-8236-115d54046fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the input and output features\n",
    "X = df.drop(\"Marks\", axis= 1)\n",
    "y = df[\"Marks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12705399-0d87-466b-b64c-6459a1563c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training ans testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120290c5-bc65-4d3b-b5fd-515bd16e877f",
   "metadata": {},
   "source": [
    "### Train the Model and Evaluate Performance\n",
    "\n",
    "- Train the model with the training dataset so that we can use the trained model to predict the marks of a student depending on the number of courses for with the student enrolled and time(in hours) spent in study.\n",
    "- Evaluate the the performance of the trained model with the metrics R2 score.\n",
    "- Evaluate the loss or residual of the trained model with the metrics Root Mean Squeared Error, Mean Squared Error and Mean Absolute Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb48443e-bcb0-4b5b-9434-263450e7e651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model and evaluate the model\n",
    "def train_and_evaluate(model):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make prediction for training and tesing data\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Print the evaluation metrics\n",
    "    print(\"=\" * 60)\n",
    "    print(\"EVALUATION METRICS FOR TRAINING DATA\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Score: {r2_score(y_train, y_train_pred): .2f}\")\n",
    "    print(f\"Mean Absolute Error(MAE): {mean_absolute_error(y_train, y_train_pred): .2f}\")\n",
    "    print(f\"Mean Squared Error(MSE): {mean_squared_error(y_train, y_train_pred): .2f}\")\n",
    "    print(f\"Root Mean Squared Error(RMSE): {np.sqrt(mean_squared_error(y_train, y_train_pred)): .2f}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"EVALUATION METRICS FOR TESTING DATA\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Score: {r2_score(y_test, y_test_pred): .2f}\")\n",
    "    print(f\"Mean Absolute Error(MAE): {mean_absolute_error(y_test, y_test_pred): .2f}\")\n",
    "    print(f\"Mean Squared Error(MSE): {mean_squared_error(y_test, y_test_pred): .2f}\")\n",
    "    print(f\"Root Mean Squared Error(RMSE): {np.sqrt(mean_squared_error(y_test, y_test_pred)): .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c843ae1-e240-4867-b945-7c360a398a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EVALUATION METRICS FOR TRAINING DATA\n",
      "============================================================\n",
      "Score:  0.80\n",
      "Mean Absolute Error(MAE):  3.23\n",
      "Mean Squared Error(MSE):  35.96\n",
      "Root Mean Squared Error(RMSE):  6.00\n",
      "============================================================\n",
      "EVALUATION METRICS FOR TESTING DATA\n",
      "============================================================\n",
      "Score:  0.69\n",
      "Mean Absolute Error(MAE):  5.68\n",
      "Mean Squared Error(MSE):  81.11\n",
      "Root Mean Squared Error(RMSE):  9.01\n"
     ]
    }
   ],
   "source": [
    "# Try SVM Regressor model to train and evalueate\n",
    "svr = SVR()\n",
    "train_and_evaluate(svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bfa29f-3129-4948-aa6f-127de7e92379",
   "metadata": {},
   "source": [
    "### Insights\n",
    "\n",
    "- **Training Score of 80%**:\n",
    "\n",
    "This means the SVR model is able to explain 80% of the variance in the training dataset, which suggests the model has learned patterns from the data well.\n",
    "\n",
    "- **Testing Score of 69%**:\n",
    "\n",
    "This is the model's performance on the test dataset (unseen data). The lower score (compared to the training score) suggests that the model's ability to generalize is less strong.\n",
    "\n",
    "The gap between the training score (80%) and the testing score (69%) suggests that the model might be overfitting to the training data. This means that the model performs very well on the training data but doesn’t generalize well to new data. This is because the model has become too specialized to the training set and has potentially captured noise or irrelevant details that don't apply to the unseen test data.\n",
    "\n",
    "#### Causes\n",
    "\n",
    "- **Insufficient Training Data**: As the dataset is small (only 100 observations) or not diverse enough, the model may not generalize well because it hasn't seen enough variability in the training data.\n",
    "- **Model Complexity**: This model might be more complex model for this data so it might fit the training data well but fail to generalize.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140ed089-bfc5-4a10-bf78-86578d50b7ae",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "- **Cross-Validation**: Use techniques like **k-fold cross-validation** to check how the model performs on different subsets of the data. This will help you ensure the model generalizes well across various parts of the data.\n",
    "- **Regularization**: Introduce regularization (e.g., L1, L2) to penalize overly complex models and reduce overfitting. For instance, in XGBoost, you can add parameters like alpha and lambda for L1 and L2 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6060d650-7c33-4ada-923b-bbbfa988afcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Score:  0.81\n"
     ]
    }
   ],
   "source": [
    "# Define KFold\n",
    "kf = KFold(n_splits= 5, shuffle= True)\n",
    "# Define Regressor model\n",
    "svr_cv = SVR()\n",
    "\n",
    "# Find cross validation score\n",
    "scores = cross_val_score(svr_cv, X, y, cv= kf, scoring= \"r2\")\n",
    "# print the mean score\n",
    "print(f\"Mean Score: {np.mean(scores): 0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7362018f-28c9-48bf-a805-727b35b1b90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best Score:  0.99\n",
      "{'C': 5, 'epsilon': 0.2, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Tune hyperparameter for regularization\n",
    "# Define parameter dictionary\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 5],\n",
    "    'epsilon': [0.1, 0.2, 0.5, 1],\n",
    "    'kernel': [\"linear\", \"rbf\", \"poly\"]\n",
    "}\n",
    "\n",
    "# Define model\n",
    "svr_ht = SVR()\n",
    "\n",
    "# Define Grid Search\n",
    "gscv = GridSearchCV(\n",
    "    estimator= svr_ht,\n",
    "    param_grid = param_grid,\n",
    "    cv= 5,\n",
    "    verbose= 1,\n",
    "    scoring= \"r2\"\n",
    ")\n",
    "# Train with different hyperparameter\n",
    "gscv.fit(X, y)\n",
    "# Get best parameter set\n",
    "best_params = gscv.best_params_\n",
    "print(f\"Best Score: {gscv.best_score_: 0.2f}\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c06deab0-a5f9-4427-8944-37e928c3669b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EVALUATION METRICS FOR TRAINING DATA\n",
      "============================================================\n",
      "Score:  0.99\n",
      "Mean Absolute Error(MAE):  0.68\n",
      "Mean Squared Error(MSE):  1.93\n",
      "Root Mean Squared Error(RMSE):  1.39\n",
      "============================================================\n",
      "EVALUATION METRICS FOR TESTING DATA\n",
      "============================================================\n",
      "Score:  0.98\n",
      "Mean Absolute Error(MAE):  1.35\n",
      "Mean Squared Error(MSE):  5.62\n",
      "Root Mean Squared Error(RMSE):  2.37\n"
     ]
    }
   ],
   "source": [
    "# Train the model with best parameter set\n",
    "model = SVR(**best_params)\n",
    "train_and_evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340edae6-a1aa-469a-bbf8-a16bb4da35fe",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The model, with a 99% training score and a 98% testing score, is performing extremely well, showing both high accuracy and good generalization. The use of the RBF kernel, C = 5, and epsilon = 0.2 is creating a balanced SVR model that fits the data effectively without significant overfitting. However, it’s still advisable to validate the model further using cross-validation and test it on more diverse datasets to ensure its robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6511067-05ce-497d-9e96-a7ea78270435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
